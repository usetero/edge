receivers:
  otlp:
    protocols:
      http:
        endpoint: 127.0.0.1:4318

  datadog:
    endpoint: 127.0.0.1:4319
    read_timeout: 60s

processors:
  batch:
    # Small batch for benchmarking - ensures requests flow through
    send_batch_size: 100
    timeout: 100ms

  filter:
    error_mode: ignore
    logs:
      log_record:
        - 'IsMatch(body, ".*authentication.*")'
        - 'IsMatch(body, ".*Payment.*")'
        - 'IsMatch(body, ".*Cache miss.*")'
        - 'IsMatch(body, ".*Cache hit.*")'
        - 'IsMatch(body, ".*error.*")'
        - 'IsMatch(body, ".*ERROR.*")'
        - 'IsMatch(body, ".*debug.*")'
        - 'IsMatch(body, ".*DEBUG.*")'
        - 'IsMatch(body, ".*HTTP request.*")'
        - 'IsMatch(body, ".*API call.*")'

  probabilistic_sampler:
    sampling_percentage: 28
    attribute_source: record
    from_attribute: body

exporters:
  otlphttp:
    endpoint: http://127.0.0.1:9999
    compression: none

service:
  telemetry:
    logs:
      level: error
  pipelines:
    logs/otlp:
      receivers: [otlp]
      processors: [filter, probabilistic_sampler, batch]
      exporters: [otlphttp]
    logs/datadog:
      receivers: [datadog]
      processors: [filter, probabilistic_sampler, batch]
      exporters: [otlphttp]
